{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "DS_Bitácora_32_PCA.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OZVp9hR_z-9"
      },
      "source": [
        "# Reducción de dimensionalidad - PCA\n",
        "\n",
        "## 1. Arreglo de Features \"A mano\"\n",
        "\n",
        "Ya hemos comentado que el tema de reducción de dimensionalidad peude pensarse como una parte del preprocesamiento, es decir, se mejoran los atributos a introducir a un modelo posteriormente. También, sirve en una etapa exploratoria, ya que reduciendo la cantidad de atributos (típicamente a dos) es más fácil visualizar un dataset. Esto era algo que aprendimos a hacer \"a mano\" al princio del segundo bloque, cuando inspeccionábamos y seleccionábamos los atributos que correlacionaban con la etiqueta de interés.\n",
        "\n",
        "A continuación les mostramos un ejemplo de un problema donde selecionamos a mano una combinación de atributos que mejora el rendimiento de un modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00P85bBZ_z-_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDTk3pR_z_K"
      },
      "source": [
        "data = pd.read_csv('DS_Bitácora_32_datosPCA.csv', index_col = 0)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOPQl6JC_z_X"
      },
      "source": [
        "plt.scatter(data['x1'], data['x2'], c = data['y'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R79m4Km_z_f"
      },
      "source": [
        "Notar que las etiquetas crecen en una dirección \"a 45 grados\" con respecto a los atributos. Si exploramos la correlación entre ellos y las etiquetas (`y`), notamos que ninguna de las dos está correlacionada a este valor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAsu4CnO_z_h"
      },
      "source": [
        "corr = data.corr(method='pearson') # .corr is used for find corelation\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
        "           xticklabels= data.columns, \n",
        "           yticklabels= data.columns,\n",
        "           cmap= 'coolwarm')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhiLB7SM_z_o"
      },
      "source": [
        "Notar que los features están altamente correlacionados entre sí y poco correlacionados con la etiqueta `y` que queremos predecir. Esto nos podría hacer creer que este dataset es de mala calidad, que `x1`, `x2` no guardan una relación con con `y`.\n",
        "\n",
        "Vamos a entrenar un árbol de decisión para predecir el valor de `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFIBwtA6_z_p"
      },
      "source": [
        "X = data[['x1', 'x2']].values\n",
        "y = data['y'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYjgtiH4_z_w"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkyGqffj_z_2"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxcvtCVn_z_9"
      },
      "source": [
        "regresor = DecisionTreeRegressor(max_depth=2)\n",
        "regresor.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApXSbcik_0AD"
      },
      "source": [
        "y_train_pred = regresor.predict(X_train)\n",
        "y_test_pred = regresor.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1MV9ILy_0AN"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_train,y_train_pred))\n",
        "print(mean_squared_error(y_test,y_test_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZFwbvxI_0AT"
      },
      "source": [
        "Notemos que el modelo no es muy bueno. Sin embargo, la información para poder predecir está en los datos y el modelo usado podría ser mucho mejor. El problema viene porque no realizamos una transformación de datos adecuada antes de alimentar el modelo.\n",
        "\n",
        "Agreguemos un nuevo atributos, que sea la resta de las anteriores. Esto lo sabemos hacer porque generamos los datos, sino no sabríamos qué combinación usar. El truco de PCA, veremos luego, es que descubrirá solo qué tiene que hacer eso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d_4xqkO_0AU"
      },
      "source": [
        "data['x_nuevo'] = data['x2'] - data['x1']\n",
        "X_new = data['x_nuevo'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP0C2N9l_0Aa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mJlLx_5_0Af"
      },
      "source": [
        "regresor = DecisionTreeRegressor(max_depth=1)\n",
        "regresor.fit(X_train.reshape(-1,1),y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uz85hNS_0Ak"
      },
      "source": [
        "y_train_pred = regresor.predict(X_train.reshape(-1,1))\n",
        "y_test_pred = regresor.predict(X_test.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga4_j-0S_0Aq"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print(mean_squared_error(y_train,y_train_pred))\n",
        "print(mean_squared_error(y_test,y_test_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai8rLPfG_0Av"
      },
      "source": [
        "La predicción, con la misma profundidad en el modelo, mejoró un montón. ¿Qué sucedió? Primero veamos la relación entre el nuevo atributo y la etiqueta `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKTUGct0_0Aw"
      },
      "source": [
        "plt.scatter(data['x_nuevo'], data['y'])\n",
        "plt.xlabel('x_nuevo')\n",
        "plt.ylabel('y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZWFaLfm_0A0"
      },
      "source": [
        "Observá que ahora el nuevo atributo mantiene una relación lineal perfecta con `y`.\n",
        "\n",
        "Y las correlaciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjqZ5j81_0A1"
      },
      "source": [
        "corr = data.corr(method='pearson') # .corr is used for find corelation\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
        "           xticklabels= data.columns, \n",
        "           yticklabels= data.columns,\n",
        "           cmap= 'coolwarm')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qskmzfet_0A5"
      },
      "source": [
        "Y también vemos que está perfectamente correlacionado con la etiqueta, no así con `x1` y `x2`.\n",
        "\n",
        "**Conclusión:** con los mismos datos, pudimos predecir mucho mejor, ya que construimos un atributo mucho más adecuado para el problema.\n",
        "\n",
        "## 2. Arreglo de Features automático\n",
        "\n",
        "PCA nos puede ayudar a preparar automaticamente los atributos, por lo que no será necesario hacer \"a mano\" lo que hicimos en la sección anterior. Existen muchas implementaciones de PCA, utilizaremos la de Scikit-Learn. Es **importantísimo** que mires la [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3rsIoq0_0A7"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_nuevo = pca.fit_transform(X) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu3-XtBZ_0A_"
      },
      "source": [
        "¿Cómo son los nuevos atributos con respecto a los originales? Esto lo podemos ver a través del atributo `components_` de la clase `PCA`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCaA6lN6_0A_"
      },
      "source": [
        "pca.components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BGk216u_0BE"
      },
      "source": [
        "Asegúrate de entender qué significa. \n",
        "\n",
        "Veamos como quedan los datos en este nuevo espacio de atributos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziuZ1qHG_0BE"
      },
      "source": [
        "plt.scatter(X_nuevo[:,0], X_nuevo[:,1], c = y)\n",
        "plt.xlabel('X_nuevo[:,0]')\n",
        "plt.ylabel('X_nuevo[:,1]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkQS42ox_0BK"
      },
      "source": [
        "Notar que ahora hay un atributo que esta muy correlacionado con la etiqueta (¿Te das cuenta cuál es? Si es necesario, realiza otro gráfico de dispersión, probando cada atributo nuevo contra `y`). Usamos ahora estos dos atributos como dataset y probamos nuevamente entrenar un modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFEHKH41_0BK"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_nuevo, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqaIn6yR_0BQ"
      },
      "source": [
        "Usamos un arbol de profundidad 1 nuevamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJy8N2Dg_0BQ"
      },
      "source": [
        "regresor2 = DecisionTreeRegressor(max_depth=1)\n",
        "regresor2.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNVHwhB5_0BV"
      },
      "source": [
        "Notemos que el error que obtenemos usando estos dos nuevos features (obtenidos a través de PCA) es mucho menor al error que hubiesemos tenido si usábamos los features originales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38mt3zyt_0BW"
      },
      "source": [
        "print(mean_squared_error(y_train,y_train_pred))\n",
        "print(mean_squared_error(y_test,y_test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh-x1-bO_0Ba"
      },
      "source": [
        "Por último, podemos ver qué atributo fue más importante al momento de predecir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nrEPUPU_0Ba"
      },
      "source": [
        "regresor2.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evrxuPMo_0Bf"
      },
      "source": [
        "¿A qué atributo corresponde la mayor importancia?¿Cómo se relaciona con lo que vimos en la primera sección?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQQJIurl_0Bf"
      },
      "source": [
        "## 3. ¡A probar con un dataset!\n",
        "\n",
        "Toma lo que hiciste el encuentro pasado y compara la aplicación de SVD con PCA. ¿Son iguales?¿Son distintas? Si corresponde, ¿en qué se parecen y en qué se diferencian?"
      ]
    }
  ]
}